RDBMS:

=================================
datatype:
The TEXT and TINYTEXT SQL data types are great for data like quotes and phone numbers. You can fit a maximum character count of 256 bytes and 64kb respectively into the TINYTEXT and TEXT data types
CHAR	256bytes	All kinds of specified texts like company abbreviations na phone numbers
VARCHAR	~64kb	All kinds of unspecified texts like names, addresses, list of items
ENUM	Unspecified	Human gender, sizes, all form discrete data
MEDIUMTEXT	~16MB	A memo or perhaps an essay
LONGTEXT	~4GB	An entire book of text
TEXT	~64kb	Phone numbers
TINYTEXT	256bytes	

Numeric Data Types and When to Use Them
When you need to perform mathematical operations on SQL data, itâ€™s time to look into a numeric data type. Numeric data types allow you to store numbers you know will be used for some mathematical expression later on.

INT
  When you need to store a number without a decimal point, use an integer. Integers store whole numbers. The count of an item may be a good example for storing as an integer. The price of a supermarket item, on the other hand, would not.
  
Name	Size (byte) per character	Potential storage consumption
Tiny BLOB	1 byte	255bytes
BLOB	2 bytes	~65KB
Medium BLOB	3 bytes	~16MB
Long BLOB	4 bytes	~4GB

what to store in BLOB TYPE?
BLOB data types are great for storing related files such as product images, Excel invoices, audio files, video clips, or any other file type. To suppose binary data like this, SQL allows blob data types sizes of several gigabytes

If youâ€™d like to store files in a SQL database type, you have four different BLOB data type options; Tiny BLOB, BLOB, Medium Blob, and Long BLOB. Each data type possesses the same characteristics other than the maximum amount you can store inside each type.




=================================================================================================
DATABASE SHARDING:
Sharding Architectures
1.Key Based Sharding
2.Horizontal or Range Based Sharding 
3. Vertical Sharding
4. Directory-Based Sharding


his technique is also known as hash-based sharding. Here, we take the value of an entity such as customer ID, customer email, IP address of a client, zip code, etc and we use this value as an input of the hash function. This process generates a hash value which is used to determine which shard we need to use to store the data. We need to keep in mind that the values entered into the hash function should all come from the same column (shard key) just to ensure that data is placed in the correct order and in a consistent manner

The downside of this method is elastic load balancing which means if you will try to add or remove the database servers dynamically it will be a difficult and expensive process. 





Horizontal or Range Based Sharding 
In this method, we split the data based on the ranges of a given value inherent in each entity
The drawback of this method is that the data may not be evenly distributed on shards.


 Vertical Sharding
In this method, we split the entire column from the table and we put those columns into new distinct tables. Data is totally independent of one partition to the other ones. Also, each partition holds both distinct rows and columns. Take the example of Twitter features. We can split different features of an entity in different shards on different machines. On Twitter users might have a profile, number of followers, and some tweets posted by his/her own. We can place the user profiles on one shard, followers in the second shard, and tweets on a third shard.

. Directory-Based Sharding
In this method, we create and maintain a lookup service or lookup table for the original database. Basically we use a shard key for lookup table and we do mapping for each entity that exists in the database
BEST ACHTECTURE   

The major drawback of this approach is the single point of failure of the lookup table.




=================================================================================================
Conceptual Design
Attributes:
   Multi-Value Attributes
   Derived Attributes
Stored Vs Derived Attributes Vs Null Value
   Derived as Current Age from dob and current date for a person
Entity Type: Department, has multiple departments of same structure
Entity Set: Collection of entities of particular Type
Key Attributes: Can have any number of keys
  A ket that is unique for each Department in an entity set
  Composite Key: Should be minimal i.e. No Subset of a key to be key itself.eg: Dept Id + name is not minimal hence not a composite key
EER Model?
Some entities without any key attribute: Called weak entity
Domain of attribute: Set of valid values the attribute can attain
Daomain of attribuute: D1*D2*D3 for subattributes of domain D1, D2( Cartesian Product)

Relation between two entity tyoes and define a relationship set
tye of relations: Uniary, Binary, Ternary
RelationShips in RDBMS Or Object Oriented Databases.

Constraints:
  Cardinality Ratios: N(Employee)----1(Department)
  Participation Constraint: as equivalent to composition in Java
  Full Participation??Budget allocated to Department and Project relationship and NOT for either Department and Project exclusively.
Identifying relationship Type?????  

Weak Entity: Entity without any key attribute eg: insurance record associated to person
Relationship: Association between Two Entities, Defined by Cardinality Constraints
Identifying Relationship??? Related to Weak Entity Type

EER(Enhaned Entity RelationShip)
Inheritence: IS_A relationship i.e. Class B is a Specilization of class of type A
as Car is a Vehicle.
Subclasses undergo type Inheritence i.e. memeber of subclass has same attributes as the SuperClass entities and participate in the same relationship type.
means the subclass should be replcable with superclass without changing the semantics/functionlities.like earth to moon example
Also the keys should be same in both super and subclass though subclass can have additional attributes though
Generalization  to Specialization is SuperClass to subClass

Predicate Defined SubClasses: where the subclasses can be differentiated on basis of some attribute called "defining the predicate"
UnionType Or Categories: When the implementation of the generalization is More Abstract as Account in Bank could be in name of individual/Group/family

Higher Order Relationship: The relation ship that cannot be breakDown to binary without loosing the meaning



Optimistic locking
Optimistic locking, also referred to as optimistic concurrency control,
allows multiple concurrent users to attempt to update the same
resource.
There are two common ways to implement optimistic locking: version
number and timestamp. Version number is generally considered to be
a better option because the server clock can be inaccurate over time.
We explain how optimistic locking works with version number.

Optimistic locking is usually faster than pessimistic locking because we
do not lock the database. However, the performance of optimistic
locking drops dramatically when concurrency is high

What are the top cache strategies?
Read data from the system:
ðŸ”¹ Cache aside
ðŸ”¹ Read through
Write data to the system:
ðŸ”¹ Write around
ðŸ”¹ Write back
ðŸ”¹ Write through




======================================================================

REDIS"
=====


in-memory, key-value data store
Redis is a popular choice for caching, session management, gaming, leaderboards, real-time analytics, geospatial, ride-hailing, chat/messaging, media streaming, and pub/sub app

Redis data types include:
Strings â€“ text or binary data up to 512MB in size
Lists â€“ a collection of Strings in the order they were added
Sets â€“ an unordered collection of strings with the ability to intersect, union, and diff other Set types
Sorted Sets â€“ Sets ordered by a value
Hashes â€“ a data structure for storing a list of fields and values
Bitmaps â€“ a data type that offers bit level operations
HyperLogLogs â€“ a probabilistic data structure to estimate the unique items in a data set
Streams - a log data structure Message queue
Geospatial - a longitude-/latitude-based entries Maps, "nearby"


====================================
ELASTIC SEARCH:
==============

Elasticsearch is a distributed search and analytics engine built on Apache Lucene
You can send data in the form of JSON documents to Elasticsearch using the API or ingestion tools such as Logstash and Amazon Kinesis Firehose. Elasticsearch automatically stores the original document and adds a searchable reference to the document in the clusterâ€™s index. You can then search and retrieve the document using the Elasticsearch API. You can also use Kibana, a visualization tool, with Elasticsearch to visualize your data and build interactive dashboards


