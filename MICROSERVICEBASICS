https://docs.microsoft.com/en-us/azure/architecture/microservices/design/interservice-communication

GET , PUT , DELETE , HEAD , OPTIONS and TRACE are idempotent
challenges for microservices:
Resiliency
There are two design patterns that can help make service-to-service network calls more resilient:

Retry. A network call may fail because of a transient fault that goes away by itself. Rather than fail outright, the caller should typically retry the operation a certain number of times, or until a configured time-out period elapses. However, if an operation is not idempotent, retries can cause unintended side effects. The original call might succeed, but the caller never gets a response. If the caller retries, the operation may be invoked twice. Generally, it's not safe to retry POST or PATCH methods, because these are not guaranteed to be idempotent.

Circuit Breaker. Too many failed requests can cause a bottleneck, as pending requests accumulate in the queue. These blocked requests might hold critical system resources such as memory, threads, database connections, and so on, which can cause cascading failures. The Circuit Breaker pattern can prevent a service from repeatedly trying an operation that is likely to fail
===
Load balancing. When service "A" calls service "B", the request must reach a running instance of service "B". In Kubernetes, the Service resource type provides a stable IP address for a group of pods. Network traffic to the service's IP address gets forwarded to a pod by means of iptable rules. By default, a random pod is chosen. A service mesh (see below) can provide more intelligent load balancing algorithms based on observed latency or other metrics
===
Distributed tracing. A single transaction may span multiple services. That can make it hard to monitor the overall performance and health of the system. Even if every service generates logs and metrics, without some way to tie them together, they are of limited use
=========
Service versioning. When a team deploys a new version of a service, they must avoid breaking any other services or external clients that depend on it. In addition, you might want to run multiple versions of a service side-by-side, and route requests to a particular version
===========
TLS encryption and mutual TLS authentication. 
=============================================================
=============================================================



two basic messaging patterns that microservices can use to communicate with other microservices.

Synchronous communication. In this pattern, a service calls an API that another service exposes, using a protocol such as HTTP or gRPC. This option is a synchronous messaging pattern because the caller waits for a response from the receiver.

Asynchronous message passing. In this pattern, a service sends message without waiting for a response, and one or more services process the message asynchronously.

It's important to distinguish between asynchronous I/O and an asynchronous protocol. Asynchronous I/O means the calling thread is not blocked while the I/O completes. That's important for performance, but is an implementation detail in terms of the architecture. An asynchronous protocol means the sender doesn't wait for a response. HTTP is a synchronous protocol, even though an HTTP client may use asynchronous I/O when it sends a request

asynchronous messaging has some advantages that can be useful in a microservices architecture:

Reduced coupling. The message sender does not need to know about the consumer.

Multiple subscribers. Using a pub/sub model, multiple consumers can subscribe to receive events. See Event-driven architecture style.

Failure isolation. If the consumer fails, the sender can still send messages. The messages will be picked up when the consumer recovers. This ability is especially useful in a microservices architecture, because each service has its own lifecycle. A service could become unavailable or be replaced with a newer version at any given time. Asynchronous messaging can handle intermittent downtime. Synchronous APIs, on the other hand, require the downstream service to be available or the operation fails.

Responsiveness. An upstream service can reply faster if it does not wait on downstream services. This is especially useful in a microservices architecture. If there is a chain of service dependencies (service A calls B, which calls C, and so on), waiting on synchronous calls can add unacceptable amounts of latency.

Load leveling. A queue can act as a buffer to level the workload, so that receivers can process messages at their own rate.

Workflows. Queues can be used to manage a workflow, by check-pointing the message after each step in the workflow.

===================================================================
A service mesh is a software layer that handles service-to-service communication. Service meshes are designed to address many of the concerns listed in the previous section, and to move responsibility for these concerns away from the microservices themselves and into a shared layer. The service mesh acts as a proxy that intercepts network communication between microservices in the cluster. Currently, the service mesh concept applies mainly to container orchestrators, rather than serverless architectures.
Service mesh is an example of the Ambassador pattern — a helper service that sends network requests on behalf of the application


the main options for a service mesh in Kubernetes are linkerd and Istio
Features for ser mesh:
Load balancing at the session level, based on observed latencies or number of outstanding requests. This can improve performance over the layer-4 load balancing that is provided by Kubernetes.

Layer-7 routing based on URL path, Host header, API version, or other application-level rules.

Retry of failed requests. A service mesh understands HTTP error codes, and can automatically retry failed requests. You can configure that maximum number of retries, along with a timeout period in order to bound the maximum latency.

Circuit breaking. If an instance consistently fails requests, the service mesh will temporarily mark it as unavailable. After a backoff period, it will try the instance again. You can configure the circuit breaker based on various criteria, such as the number of consecutive failures,

Service mesh captures metrics about interservice calls, such as the request volume, latency, error and success rates, and response sizes. The service mesh also enables distributed tracing by adding correlation information for each hop in a request.

Mutual TLS Authentication for service-to-service calls.

==================================================================



Deploy services:
  Blue-Green , Canary,Multiservice
  
  How to design a secure web API access for your
website?
When we open web API access to users, we need to make sure each
API call is authenticated. This means the user must be who they claim
to be.
In this post, we explore two common ways:
1. Token based authentication
2. HMAC (Hash-based Message Authentication Code) authenticatio

How do microservices collaborate and interact with each
other?
There are two ways: 𝐨𝐫𝐜𝐡𝐞𝐬𝐭𝐫𝐚𝐭𝐢𝐨𝐧 and 𝐜𝐡𝐨𝐫𝐞𝐨𝐠𝐫𝐚𝐩𝐡𝐲.

The benefits of orchestration:
1. Reliability - orchestration has built-in transaction management and
error handling, while choreography is point-to-point communications
and the fault tolerance scenarios are much more complicated.
2. Scalability - when adding a new service into orchestration, only the
orchestrator needs to modify the interaction rules, while in
choreography all the interacting services need to be modified.
Some limitations of orchestration:
1. Performance - all the services talk via a centralized orchestrator, so
latency is higher than it is with choreography. Also, the throughput is
bound to the capacity of the orchestrator.
2. Single point of failure - if the orchestrator goes down, no services
can talk to each other. To mitigate this, the orchestrator must be highly
available.

🔹Containerization is considered to be a lightweight version of
virtualization, which virtualizes the operating system instead of
hardware. Without the hypervisor, the containers enjoy faster resource
provisioning. All the resources (including code, dependencies) that are
40
needed to run the application or microservice are packaged together,
so that the applications can run anywhere.
