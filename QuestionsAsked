

SUMMARY OF BOOKS:
=================

https://github.com/keyvanakbary/learning-notes/tree/master/books



https://leetcode.com/discuss/interview-question/1140451/helpful-list-of-leetcode-posts-on-system-design-at-facebook-google-amazon-uber-microsoft

Storage estimation in system design???
like size of image etcc, QPS

System Design API Design to functonal requirement

===========================

Role based Authentication in spring
============================

role based authentication:

https://www.baeldung.com/role-and-privilege-for-spring-security-registration



Let's start with our entities. We have three main entities:

The User
The Role represents the high-level roles of the user in the system. Each role will have a set of low-level privileges.
The Privilege represents a low-level, granular privilege/authority in the system.

We're creating the privileges.
Then we're creating the roles and assigning the privileges to them.
Finally, we're creating a user and assigning a role to it



============================
OAuth
completable future for Async


database sharding
===================
1. Key based sharding, also known as hash based sharding, involves using a value taken from newly written data — such as a customer’s ID number, a client application’s IP address, a ZIP code, etc. — and plugging it into a hash function to determine which shard the data should go to. A hash function is a function that takes as input a piece of data (for example, a customer email) and outputs a discrete value, known as a hash value. In the case of sharding, the hash value is a shard ID used to determine which shard the incoming data will be stored on
-ve :
  it can make things tricky when trying to dynamically add or remove additional servers to a database. As you add servers, each one will need a corresponding hash value and many of your existing entries, if not all of them, will need to be remapped to their new, correct hash value and then migrated to the appropriate server
+ve : The main appeal of this strategy is that it can be used to evenly distribute data so as to prevent hotspots. Also, because it distributes data algorithmically, there’s no need to maintain a map of where all the data is located, as is necessary with other strategies like range or directory based sharding.

2.Range based sharding:
   On the other hand, range based sharding doesn’t protect data from being unevenly distributed, leading to the aforementioned database hotspots
   
3. Directory ased sadding:
   Directory based sharding is a good choice over range based sharding in cases where the shard key has a low cardinality — meaning, it has a low number of possible values — and it doesn’t make sense for a shard to store a range of keys. Note that it’s also distinct from key based sharding in that it doesn’t process the shard key through a hash function; it just checks the key against a lookup table to see where the data needs to be written.
   
   
 


==================
A/B , unit testing
SLA time,UP Time
Role based Authntication
Datamodel/availibilty
1. comparable vs comparator
2. default in java8
3. groupBy in stream

4. why kafka and one time gaurantee
=========================================
 Kafka has several ways to deal with these potential issues and enable its exactly-once delivery semantics.
   1. Idempotent producer: With idempotency enabled in Kafka, all messages are tagged with a producer ID and a unique sequence number. If the producer tries to send a message again, the topic will only accept the message if the producer ID and sequence number are distinct. This prevents the same message from being accepted twice after a failure or crash.
   2. Transactions: As the general concept of database transactions, Kafka transactions use an “all or nothing” approach: either all of the messages in a transaction are committed, or none of them are. Kafka 0.11 introduces the transaction coordinator and transaction log components that enable transactions in Kafka to be atomic. More specifically, the transaction coordinator keeps track of producer IDs to avoid “zombie instances” that are still running after a system restart, while the transaction log records the state of each transaction at each step of the process.
=========================================
5. Api by role in spring security
6. real time data processing in videos
7. diamond problem
8. static vs singleton
9. rest endpoints and design service
10. Design API for cowin App.
11. lru cache
12. chess / snakeladder/parking
13. job schedular
14.Stock leetcode
15. make paranthesis valid
16. PUT vs patch
minstack
minimum meeting rooms
trapping wter
spiral matrix
producer consumer 
threadlocal
volatile vs atomic
thread communication using synchronized
circuit breaker
resiliency pattern


WebSocket Server
==================
WebSockets is a thin layer built on top of TCP/IP, so anything beyond the basic handshake and specification for message framing is really something that needs to be handled either on a per-application or per-library basis.
===================


Payment Gateway
MultiMediaPlayer
Distrbute logging in micro
Producer-Consumer using wait notify


A Thread Pool is a famous design pattern which consists of a number N of threads running a number M of jobs concurrently. The main motivation behind using the pattern is to avoid the overhead associated with creating and destroying threads. The more straight-forward approach of handling M independent jobs would be to spawn a thread for each job and destroy the thread once the job is executed.
